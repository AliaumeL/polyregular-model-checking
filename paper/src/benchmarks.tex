% LTeX: language=EN
\section{Benchmarks}
\label{sec:benchmarks}

\AP We implemented all the transformations expressed in this paper in a
\texttt{Haskell} program. To measure the complexity of these transformations,
we associated to a \kl{high-level for-program} the following parameters: its
\emph{size} (number of control flow statements), its \intro{loop depth} (the
maximum number of nested loops), and its \intro{boolean depth} (the maximum
number of boolean variables visible at any point in the program). We compute
the same parameters for the corresponding \kl{simple for-program}. In the case
of \kl{first-order interpretations}, we only compute its \emph{size} (number of
nodes in the formula) and its \kl{quantifier rank}. This allowed us to
benchmark our transformations on a small set of programs that we present in
\cref{tab:benchmarks}. Then, we used several existing solvers to verify basic
\kl{first-order Hoare triples} for these programs. Because the goal of this
paper was to showcase the usage of the theory of \kl{polyregular functions}, we
did not focus on optimizing the input for a particular solver: all solvers
(except \kl{MONA}) were given an input in the \texttt{SMT-LIB} format. We
illustrate in \cref{tab:timings} the behaviour of the solvers on various
verification tasks, with a timeout of $5$ seconds for every solver.

\begin{table}[t]
    \caption{Benchmark results for the transformations. 
        Here \kl[for-program]{FP} is a \kl{for-program},
        \kl[simple for-program]{S.FP} is a \kl{simple for-program},
        and \kl[first-order interpretation]{$\FO$-I} is a \kl{first-order interpretation}.
        The columns \textbf{l.d.}, \textbf{b.d.} and \textbf{q.r.}
        stand respectively for the \kl{loop depth}, 
        \kl{boolean depth} and \kl{quantifier rank}.
    }
    \label{tab:benchmarks}
    \centering
    \input{figs/benches.tex}
\end{table}

\begin{table}
    \caption{Verification of \kl{first-order Hoare triples} over 
        sample \kl{for-programs}. We specify the preconditions and postconditions
        as regular languages, writing $\mathcal{L}_{ab}$ as a shorthand
        for $\mathcal{D}^*ab\mathcal{D}^*$,
        and similarly for $\mathcal{L}_{aa}$, $\mathcal{L}_{ba}$, etc.
        In the columns corresponding to the solvers, a checkmark
        indicates a positive reply,
        a cross mark indicates a negative reply,
        and a question mark indicates a timeout
        or a memory exhaustion.
        We indicate the size and the \kl{quantifier rank} (\textbf{q.r.})
        of the \kl{first-order formulas} that are fed to the solvers.
    }
    \label{tab:timings}
    \centering
    \input{figs/timings.tex}
\end{table}

\paragraph{Observations on the Compilation Process.} Let us highlight that in
the simplest cases of \cref{tab:benchmarks}, our compilation procedure is able
to eliminate all boolean variables, thus producing a \emph{quantifier-free}
formula. This is the case for the \texttt{identity.pr}, \texttt{reverse.pr} and
\texttt{prefixes.pr} programs, respectively computing the identity function,
the word reversal function, and the list of all prefixes.

We can observe that the \kl{boolean depth} of the \kl{simple for-program} is a
good indicator of the \kl{quantifier rank} of the generated \kl{first-order
interpretation}. Furthermore, we demonstrate the \kl{elimination of literals}
is responsible for a significant increase in the complexity of the formulas, as
one can see in the \texttt{assets/HighLevel/litteral\_test.pr} benchmark. This
is explained by the fact that the elimination of literals introduces a
\emph{sequential} structure in the program which is simulated by introducing
boolean variables. We found it interesting that our compilation process is
non-symmetric when transforming \kl{high-level for-programs} into \kl{simple
for-programs}: this can be seen in the \texttt{get\_first\_word.pr} and
\texttt{get\_last\_word.pr}, leading to vastly different \kl{quantifier ranks}
for the resulting \kl{first-order interpretations}, although these programs are
very similar in structure and behaviour.

\paragraph{Observations on the Solver Performance.} We can observe in
\cref{tab:timings} that the solvers are complementary. Indeed, the \kl{MONA}
solver is theoretically complete, but can run out of memory and be slower than
the other solvers on some specific instances. We can also see that the goals
generated have reasonable size and \kl{quantifier rank}. A negative result is
the inability of all solvers to witness the fact that if a word $w$ contains
$ab$ as a subword, then the concatenation of all its subwords containing $ab$
as a (scattered) subword does contain $ab$ as a subword. Understanding this
result would require further investigation and its resolution may depend on a
more refined encoding of our proof obligations.
