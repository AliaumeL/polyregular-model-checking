% LTeX: language=EN
\section{Conclusion}
\label{sec:conclusion}

We have show that the theory of \kl{polyregular functions} can be used to
verify close to real-world programs, and have implemented a prototype tool that
can discharge simple verification goals to existing solvers. We believe that
there is potential for further investigations in this direction.

\paragraph{Optimizations.} The benchmarks indicate that one of the most
promising source of optimizations is managing the \kl{boolean depth} of the
generated \kl{simple for-programs} during compilation. This can be achieved by
post-compilation optimizations (constant propagation, dead code elimination),
or by improving the code generation mechanism itself, which are low-hanging
fruits for future work. One source of the boolean variables seems to be the
\kl{elimination of Literal Equality} step (\ref{item:lit_elim}), which could be
mitigated by adding explicit successor and predecessor predicates to the
language of \kl{simple for-programs}.

At the level of \kl{first-order interpretations}, we have identified several
directions for improving their efficiency. One optimization is computing the
sequential composition of programs in a way that minimizes the number of
quantified boolean variables. Similarly, there seems to be potential for
performing direct substitutions instead of quantifying over the variables in a
lot of cases. Finally, our current approach for handling loops introduces
universal quantifiers, whose number could be reduced by exploiting the
monotonicity of the state transformations.
    
\paragraph{Solver Integration.} There is a lot of potential for optimizing the
input and parameters of the solvers for our particular use-case. An interesting
research direction would be to reduce the verification problem to emptiness of
LTL formulas, allowing us to use LTL solvers such as SPOT \cite{SPOT}.

\paragraph{Modular Verification.} The benchmarks show that one of the main
bottlenecks of our approach is the expansion of loops (whether in the
translation to \kl{simple for-programs} or in the translation to
\kl{first-order interpretations}). For this reason, the ability to verify
statements of the form \texttt{for (i, e) in enumerate(f(x)) do s done}, based
on a specification of $f$ given as a Hoare triple, would be a significant
improvement. However, it remains unclear how to integrate such modular
verification in our current approach.

\paragraph{Language Design.} As mentioned in \cref{sec:high-level},
\kl{for-programs} extended with unrestricted booleans also enjoy a decidable
verification of Hoare triples. However, the verification algorithm uses of
monadic second-order logic (MSO) over words instead of first-order logic. While
this prohibits the use of traditional SMT solvers, this logic can be handled by
the \kl{MONA} solver, and it might be interesting to implement and benchmark
the unrestricted version of the language. 

Another interesting extension of the language would be to allow the use of
complex types, such as pairs and records. This would make the language closer
to real use cases such as configuration management and data processing. It
would require extending the specification language to structured data types,
bypassing the current limitation that we can only verify string-to-string
transformations.


\paragraph{Integration with Existing Tools.} It would be a natural next step to
integrate our tool inside frameworks for program verification or testing. This
could be by checking goals generated by a tool such as \texttt{Why3}
\cite{Why3}, or by verifying properties of Python programs using decorated
functions.
